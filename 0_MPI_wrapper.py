"""
Distribute pipeline processes across the cluster.
"""

import sys
import os
from glob import glob
from mpi4py import MPI
from seqUtils import convert_fasta, ambig_dict
from datetime import datetime

import inspect  # For returning the line number
def lineno():
	return inspect.currentframe().f_back.f_lineno

# Give process awareness of it's rank
my_rank = MPI.COMM_WORLD.Get_rank()
nprocs = MPI.COMM_WORLD.Get_size()

def timestamp(msg):
	print '[%s] (rank=%d/%d) %s' % (datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 
			my_rank,
			nprocs,
			msg)

refpath = '/usr/local/share/miseq/refs/cfe'	# Consensus B reference sequence
root = sys.argv[1]				# Path to the folder containing fastq files
mode = sys.argv[2] 				# Nextera or Amplicon
qCutoff = int(sys.argv[3])

# For each fastq file, map sequence to reference sequences: 1_mapping(refseq,files[i])
files = glob(root + '/*R1*.fastq')
for i in range(len(files)):
	if i % nprocs != my_rank:
		continue
	filename = files[i].split('/')[-1]
	timestamp('1_mapping %s' % filename)
	os.system("python 1_mapping.py {} {}".format(refpath, files[i], qCutoff))

MPI.COMM_WORLD.Barrier()
if my_rank == 0:
	timestamp('MPI.COMM_WORLD.Barrier() #1 passed\n')

# For each remapped SAM, generate CSFs (done), generate pileup(Need to be done)
#files = glob(root + '/*.remap.sam')

# Rename to bam
#for i in range(len(files)):
#	samfile = files[i]
        #bamfile = samfile.replace('.sam', '.bam')
        #os.system('samtools view -bt %s.fasta.fai %s > %s 2>/dev/null' % (ref, samfile, bamfile))
        #os.system('samtools sort %s %s.sorted' % (bamfile, bamfile))
        #os.system('samtools mpileup -A %s.sorted.bam > %s.pileup 2>/dev/null' % (bamfile, bamfile))
        #os.system('python pileup2conseq_v2.py %s.pileup' % bamfile)
#	pass


for i in range(len(files)):

	# Allocate the subset of remap.sam files properly to this process
	if i % nprocs != my_rank:
		continue

	filename = files[i].split('/')[-1]

	# For each q-cutoff, generate fasta for amplicon, OR a csf file for Nextera
	for qcut in [0, 10, 15, 20]:
		timestamp('2_sam2fasta %s %d %s' % (filename, qcut, mode))
		os.system('python 2_sam2fasta_with_base_censoring.py %s %d %s' % (files[i], qcut, mode))

MPI.COMM_WORLD.Barrier()

if my_rank == 0:
	timestamp('MPI.COMM_WORLD.Barrier() #2 passed\n')

# Fpr amplicon sequencing runs, compute g2p scores for env-mapped FASTAs
if mode == 'Amplicon':
	files = glob(root + '/*env*.fasta')

	for i, file in enumerate(files):

		# Distribute g2p scoring amongst each process
		if i % nprocs != my_rank:
			continue

		filename = files[i].split('/')[-1]
		timestamp('3_g2p_scoring %s (Amplicon)' % filename)

		# Generate v3prot and badV3 files from env-specific fasta
		os.system('python 3_g2p_scoring.py %s' % file)


# Generate amino acid count CSVs from fastas (for Amplicon) OR csf (for Nextera)
files_to_process = ""
if mode == 'Amplicon':
	files_to_process = root+'/*.fasta'
else:
	files_to_process = root+'/*.csf'

#files = glob(root+'/*.fasta' if mode == 'Amplicon' else root+'/*.csf')
files = glob(files_to_process)

for i, file in enumerate(files):
	if i % nprocs != my_rank:
		continue
	filename = files[i].split('/')[-1]

	# 5_amino_freqs: generates frequency per coordinate data
	# (Subsamples to generate consensus, which is used as a guide for putting in)

	# THIS IS BUGGY?! The alignment ignores indels...??

	# Input: fasta / csf files
	# Output: nuc.csv / amino.csv files
	timestamp('5_amino_freqs %s %s' % (filename, mode))
	os.system('python 5_amino_freqs.py %s %s' % (file, mode))

# Wait for all threads to complete
MPI.COMM_WORLD.Barrier()

if my_rank == 0:
	timestamp('MPI.COMM_WORLD.Barrier() #3 passed\n')

MPI.Finalize()

# Take a fasta file handle as input, along with the desired FPR-cutoff and min count
def prop_x4 (handle, cutoff, min_count):
	total_count = 0
	total_x4_count = 0

	# >F00309-IL_variant_0_count_27_fpr_4.0
	for h, s in fasta:
		tokens = h.split('_')
		try:
			variant = int(tokens[tokens.index('variant')+1])
			count = int(tokens[tokens.index('count')+1])
			fpr = float(tokens[tokens.index('fpr')+1])
		except:
			continue

		if count <= min_count:
			continue

		total_count += count
		if fpr < cutoff:
			total_x4_count += count

	return (total_x4_count, total_count)

# Only the first process will generate the _g2p.csv file
if my_rank == 0 and mode == 'Amplicon':
	timestamp('Process 0 is generating _g2p.csv')

	outfile = open(root+'/_g2p.csv', 'w')
	outfile.write('sample,q.cut,fpr.cut,min.count,x4.count,total.count,prop.x4\n')

	# v3prot files were generated by 3_g2p_scoring.py
	files = glob(root + '/*.v3prot')
	for file in files:

		# F00060-IL.HIV1B-env.20.v3prot
		filename = file.split('/')[-1]
		sample, region, qcut = filename.split('.')[:3]
		qcut = int(qcut)

		for mincount in [0, 1, 3, 50]:
			for fprcutoff in [3.0, 3.5, 4.0, 5.0, 5.75, 7.5]:

				# Open .v3prot file (fasta format)
				infile = open(file, 'rU')
				lines = infile.readlines()

				fasta = ""
				if len(lines) > 0:
					fasta = convert_fasta(lines)
				else:
					fasta = []
				infile.close()
				
				# Pass v3prot filehandle to prop_x4 + fprcutoff / mincount parameters
				if len(fasta) > 0:
					x4_count, total_count = prop_x4(infile, fprcutoff, mincount)
				else:
					x4_count = 0
					total_count = 0

				proportion_x4 = ""
				if total_count <= 0:
					proportion_X4 = 'NA'
				else:
					proportion_X4 = str(x4_count/float(total_count))

				outfile.write('%s,%d,%f,%d,%d,%d,%s\n' % (sample, qcut, fprcutoff, 
					mincount, x4_count, total_count, proportion_X4))
	outfile.close()

# Rows to columns transformation for Luke
if my_rank == 0 and mode == 'Amplicon':
	g2p_path = root + '/_g2p.csv'
	timestamp('Creating column representation of %s' % (g2p_path))
	os.system("python convert_g2p_to_column_representation.py {} > {}.columned".format(g2p_path, g2p_path))

# Generate consensus sequence
if my_rank == 0:

	# ERIC: Guin prefers 20% to approximate population sequencing
	# We may change this - or make multiple parameters for the future
	thresholds = [0.20]
	outfile = open(root+'/_nuc_consensus.fasta', 'w')

	# Open *.nuc.csv files generated by 5_amino_freqs?
	files = glob('%s/*.nuc.csv' % root)
	for file in files:
		filename = file.split('/')[-1]
		sample, region, qcut = filename.split('.')[:3]

		# infile comes from *nuc.csv file
		infile = open(file, 'rU')
		header = infile.next()
		conseqs = dict([(x, '') for x in thresholds])
		
		# For each line in the base frequency file (*.nuc.csv files)
		for line in infile:

			# Col 0 is the coordinate, Cols 1-5 are the num occurences of ACGT-
			tokens = map(int, line.strip('\n').split(','))
			pos = tokens[0]
			counts = [(count, 'ACGT-'[i]) for i, count in enumerate(tokens[1:])]
			total_count = sum([count for count, nuc in counts])

			# Populate freqs with (Frequency, character) data
			freqs = [(count/float(total_count), nuc) for count, nuc in counts]
			
			# Interpret any character above threshold percentage as real (Is this HAPPENING??)
			for threshold in thresholds:

				# ERIC: Old code didn't filter by threshold
				#passed = [nuc for f, nuc in freqs]
				passed = []
				for frequency, nuc in freqs:
					if frequency >= threshold:
						passed.append(nuc)

				# If there is only a single majority character, it is concatenated to the consensus
				# Note: this will capture areas where gaps are the only character exceeding threshold
				if len(passed) == 1:
					conseqs[threshold] += passed[0]
				else:
					# passed contains all characters that exceed the threshold
					passed.sort()

					# DEBUG - ambig_dict can't handle gaps ('-' characters)
					# BUG: In Nextera, gaps are everywhere, and so everything shows up as a gap!
					if '-' in set(passed) or ''.join(passed) == "":
						conseqs[threshold] += 'N'
					else:
						conseqs[threshold] += ambig_dict[''.join(passed)]
				
		for threshold, conseq in conseqs.iteritems():
			outfile.write('>%s_%s_Qcutoff_%s_mixtureCutoff_%f\n%s\n' % (sample, region, qcut, threshold, conseq))
	outfile.close()
